{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7c98ab",
   "metadata": {},
   "outputs": [],
   "source": [
    " from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port','0'). \\\n",
    "config(\"spark.sql.warehouse.dir\", \"/user/itv014119/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41911355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g01.itversity.com:36695\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f78407b5cc0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be26f96d",
   "metadata": {},
   "source": [
    "### Creating a spark session and entering sample data n schema for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409d35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\n",
    "    (1,'Arun',32,30),\n",
    "    (2,'John',40,45),\n",
    "    (3,None,55,35),\n",
    "    (4,'David',60,29),\n",
    "    (5,'Beckam',70,80),\n",
    "    (None,'Raju',39,69),\n",
    "    (8,'Senpai',None,99),\n",
    "    (9,'Nanami',20,None),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a83693",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_schema = \"rollno int,name string,phy int,mat int\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6190086",
   "metadata": {},
   "source": [
    "### Creating a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1fd10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = spark.createDataFrame(data=sample,schema=s_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b83ed8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----+\n",
      "|rollno|  name| phy| mat|\n",
      "+------+------+----+----+\n",
      "|     1|  Arun|  32|  30|\n",
      "|     2|  John|  40|  45|\n",
      "|     3|  null|  55|  35|\n",
      "|     4| David|  60|  29|\n",
      "|     5|Beckam|  70|  80|\n",
      "|  null|  Raju|  39|  69|\n",
      "|     8|Senpai|null|  99|\n",
      "|     9|Nanami|  20|null|\n",
      "+------+------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e167f",
   "metadata": {},
   "source": [
    "### Dealing with Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c585e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_phy = sample_df.selectExpr(\"mean(phy)\").collect()[0][0]\n",
    "mean_mat = sample_df.selectExpr(\"mean(mat)\").collect()[0][0]\n",
    "\n",
    "Updated_df = sample_df.fillna({'rollno':0,'name':'NA','phy':mean_phy,'mat':mean_mat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e049e7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>rollno</th><th>name</th><th>phy</th><th>mat</th></tr>\n",
       "<tr><td>1</td><td>Arun</td><td>32</td><td>30</td></tr>\n",
       "<tr><td>2</td><td>John</td><td>40</td><td>45</td></tr>\n",
       "<tr><td>3</td><td>NA</td><td>55</td><td>35</td></tr>\n",
       "<tr><td>4</td><td>David</td><td>60</td><td>29</td></tr>\n",
       "<tr><td>5</td><td>Beckam</td><td>70</td><td>80</td></tr>\n",
       "<tr><td>0</td><td>Raju</td><td>39</td><td>69</td></tr>\n",
       "<tr><td>8</td><td>Senpai</td><td>45</td><td>99</td></tr>\n",
       "<tr><td>9</td><td>Nanami</td><td>20</td><td>55</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+------+---+---+\n",
       "|rollno|  name|phy|mat|\n",
       "+------+------+---+---+\n",
       "|     1|  Arun| 32| 30|\n",
       "|     2|  John| 40| 45|\n",
       "|     3|    NA| 55| 35|\n",
       "|     4| David| 60| 29|\n",
       "|     5|Beckam| 70| 80|\n",
       "|     0|  Raju| 39| 69|\n",
       "|     8|Senpai| 45| 99|\n",
       "|     9|Nanami| 20| 55|\n",
       "+------+------+---+---+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Updated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ae1bf",
   "metadata": {},
   "source": [
    "### Renaming and creatin a new column \"total\" as total of two subjects using withColumn and expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee98617",
   "metadata": {},
   "outputs": [],
   "source": [
    "Renamed_df = Updated_df.withColumnRenamed(\"mat\",\"chem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24bb3f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+----+\n",
      "|rollno|  name|phy|chem|\n",
      "+------+------+---+----+\n",
      "|     1|  Arun| 32|  30|\n",
      "|     2|  John| 40|  45|\n",
      "|     3|    NA| 55|  35|\n",
      "|     4| David| 60|  29|\n",
      "|     5|Beckam| 70|  80|\n",
      "|     0|  Raju| 39|  69|\n",
      "|     8|Senpai| 45|  99|\n",
      "|     9|Nanami| 20|  55|\n",
      "+------+------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Renamed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d59a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "#importing this since its sql expression as argumentsnot a default in py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "982e6f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = Renamed_df.withColumn(\"total\",expr(\"phy+chem\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae968d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+----+-----+\n",
      "|rollno|  name|phy|chem|total|\n",
      "+------+------+---+----+-----+\n",
      "|     1|  Arun| 32|  30|   62|\n",
      "|     2|  John| 40|  45|   85|\n",
      "|     3|    NA| 55|  35|   90|\n",
      "|     4| David| 60|  29|   89|\n",
      "|     5|Beckam| 70|  80|  150|\n",
      "|     0|  Raju| 39|  69|  108|\n",
      "|     8|Senpai| 45|  99|  144|\n",
      "|     9|Nanami| 20|  55|   75|\n",
      "+------+------+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b310f7d6",
   "metadata": {},
   "source": [
    "## Knowing how many partitions used and repartitioning it to a single file for writing back to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f356b78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfe4a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = new_df.repartition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aec62714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b061d",
   "metadata": {},
   "source": [
    "### Writing my file to disk (default is json am writing in csvand for compression technique using gzip isntead of deault snappy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47a4a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.write \\\n",
    ".format(\"csv\") \\\n",
    ".mode(\"overwrite\") \\\n",
    ".option(\"header\",True) \\\n",
    ".option(\"comrpession\",\"gzip\") \\\n",
    ".option(\"Path\",'/user/itv014119/sample') \\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4271373d",
   "metadata": {},
   "source": [
    "### Reading the data from disk since I loaded the header on previous writes using it to read header from it, inferschema is not preferable but to showcase i used it now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e68ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_sample = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"header\",True) \\\n",
    ".option(\"inferSchema\",True) \\\n",
    ".load(\"/user/itv014119/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cc39a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+----+-----+\n",
      "|rollno|  name|phy|chem|total|\n",
      "+------+------+---+----+-----+\n",
      "|     1|  Arun| 32|  30|   62|\n",
      "|     2|  John| 40|  45|   85|\n",
      "|     3|    NA| 55|  35|   90|\n",
      "|     4| David| 60|  29|   89|\n",
      "|     5|Beckam| 70|  80|  150|\n",
      "|     0|  Raju| 39|  69|  108|\n",
      "|     8|Senpai| 45|  99|  144|\n",
      "|     9|Nanami| 20|  55|   75|\n",
      "+------+------+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reading_sample.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe9d9dc",
   "metadata": {},
   "source": [
    "### Joints 2 tables customers table and orders table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ace5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_schema = \"id long,date string,custid long,status string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2ba7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".schema(order_schema) \\\n",
    ".load(\"/public/trendytech/orders/orders_1gb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60497f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+---------------+\n",
      "| id|                date|custid|         status|\n",
      "+---+--------------------+------+---------------+\n",
      "|  1|2013-07-25 00:00:...| 11599|         CLOSED|\n",
      "|  2|2013-07-25 00:00:...|   256|PENDING_PAYMENT|\n",
      "|  3|2013-07-25 00:00:...| 12111|       COMPLETE|\n",
      "+---+--------------------+------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47f9200",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_schema = \"custids long,fname string,lname string,username string,pwd string,city string,state string,pincode string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b1b3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".schema(customer_schema) \\\n",
    ".load(\"/public/trendytech/retail_db/customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df8013d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+---------+---------+--------------------+-----------+-------+\n",
      "|custids|  fname|    lname| username|      pwd|                city|      state|pincode|\n",
      "+-------+-------+---------+---------+---------+--------------------+-----------+-------+\n",
      "|      1|Richard|Hernandez|XXXXXXXXX|XXXXXXXXX|  6303 Heather Plaza|Brownsville|     TX|\n",
      "|      2|   Mary|  Barrett|XXXXXXXXX|XXXXXXXXX|9526 Noble Embers...|  Littleton|     CO|\n",
      "|      3|    Ann|    Smith|XXXXXXXXX|XXXXXXXXX|3422 Blue Pioneer...|     Caguas|     PR|\n",
      "+-------+-------+---------+---------+---------+--------------------+-----------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07aa9c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68883"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_df.distinct().count()\n",
    "\n",
    "#Wide transformation this has involved 200 shuffle partitions on the backend to get this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d34e5b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12435"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bb04261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+---------------+-------+---------+-----------+---------+---------+--------------------+-------------+-------+\n",
      "| id|                date|custid|         status|custids|    fname|      lname| username|      pwd|                city|        state|pincode|\n",
      "+---+--------------------+------+---------------+-------+---------+-----------+---------+---------+--------------------+-------------+-------+\n",
      "|  1|2013-07-25 00:00:...| 11599|         CLOSED|  11599|     Mary|     Malone|XXXXXXXXX|XXXXXXXXX|8708 Indian Horse...|      Hickory|     NC|\n",
      "|  2|2013-07-25 00:00:...|   256|PENDING_PAYMENT|    256|    David|  Rodriguez|XXXXXXXXX|XXXXXXXXX|7605 Tawny Horse ...|      Chicago|     IL|\n",
      "|  3|2013-07-25 00:00:...| 12111|       COMPLETE|  12111|    Amber|     Franco|XXXXXXXXX|XXXXXXXXX|8766 Clear Prairi...|   Santa Cruz|     CA|\n",
      "|  4|2013-07-25 00:00:...|  8827|         CLOSED|   8827|    Brian|     Wilson|XXXXXXXXX|XXXXXXXXX|   8396 High Corners|  San Antonio|     TX|\n",
      "|  5|2013-07-25 00:00:...| 11318|       COMPLETE|  11318|     Mary|      Henry|XXXXXXXXX|XXXXXXXXX|3047 Silent Ember...|       Caguas|     PR|\n",
      "|  6|2013-07-25 00:00:...|  7130|       COMPLETE|   7130|    Alice|      Smith|XXXXXXXXX|XXXXXXXXX|      8852 Iron Port|     Brooklyn|     NY|\n",
      "|  7|2013-07-25 00:00:...|  4530|       COMPLETE|   4530|     Mary|      Smith|XXXXXXXXX|XXXXXXXXX|1073 Green Leaf G...|        Miami|     FL|\n",
      "|  8|2013-07-25 00:00:...|  2911|     PROCESSING|   2911|     Mary|      Smith|XXXXXXXXX|XXXXXXXXX|9166 Golden Necta...|       Caguas|     PR|\n",
      "|  9|2013-07-25 00:00:...|  5657|PENDING_PAYMENT|   5657|     Mary|      James|XXXXXXXXX|XXXXXXXXX|  1389 Dusty Circuit|     Lakewood|     OH|\n",
      "| 10|2013-07-25 00:00:...|  5648|PENDING_PAYMENT|   5648|   Joshua|      Smith|XXXXXXXXX|XXXXXXXXX|864 Iron Spring S...|      Memphis|     TN|\n",
      "| 11|2013-07-25 00:00:...|   918| PAYMENT_REVIEW|    918|   Nathan|      Smith|XXXXXXXXX|XXXXXXXXX|    9627 Honey Trail|       Caguas|     PR|\n",
      "| 12|2013-07-25 00:00:...|  1837|         CLOSED|   1837|     Mary|       Vega|XXXXXXXXX|XXXXXXXXX|  4312 Bright Corner|       Caguas|     PR|\n",
      "| 13|2013-07-25 00:00:...|  9149|PENDING_PAYMENT|   9149|   Ronald|  Whitehead|XXXXXXXXX|XXXXXXXXX|6789 Round Robin ...|    Santa Ana|     CA|\n",
      "| 14|2013-07-25 00:00:...|  9842|     PROCESSING|   9842|     Mary|      Smith|XXXXXXXXX|XXXXXXXXX|454 Lazy Branch F...|       Caguas|     PR|\n",
      "| 15|2013-07-25 00:00:...|  2568|       COMPLETE|   2568|    Maria|      Smith|XXXXXXXXX|XXXXXXXXX|   3544 Fallen Mount|      Memphis|     TN|\n",
      "| 16|2013-07-25 00:00:...|  7276|PENDING_PAYMENT|   7276|   Pamela|      Smith|XXXXXXXXX|XXXXXXXXX|    9243 Old Gardens|       Caguas|     PR|\n",
      "| 17|2013-07-25 00:00:...|  2667|       COMPLETE|   2667|    Tammy|      Smith|XXXXXXXXX|XXXXXXXXX|   8906 Rustic Mall |   Sun Valley|     CA|\n",
      "| 18|2013-07-25 00:00:...|  1205|         CLOSED|   1205|     Mary|     Powell|XXXXXXXXX|XXXXXXXXX|9299 Quiet Pionee...|        Miami|     FL|\n",
      "| 19|2013-07-25 00:00:...|  9488|PENDING_PAYMENT|   9488|     Mary|      Smith|XXXXXXXXX|XXXXXXXXX|    9758 Foggy Range|      Hialeah|     FL|\n",
      "| 20|2013-07-25 00:00:...|  9198|     PROCESSING|   9198|    David|       Kerr|XXXXXXXXX|XXXXXXXXX|7312 Crystal Will...|Bowling Green|     KY|\n",
      "| 21|2013-07-25 00:00:...|  2711|        PENDING|   2711|    Alice|  Rodriguez|XXXXXXXXX|XXXXXXXXX|2734 Dusty Blosso...|        Bronx|     NY|\n",
      "| 22|2013-07-25 00:00:...|   333|       COMPLETE|    333|Elizabeth|   Ferguson|XXXXXXXXX|XXXXXXXXX|  6847 Broad Orchard|       Caguas|     PR|\n",
      "| 23|2013-07-25 00:00:...|  4367|PENDING_PAYMENT|   4367| Danielle|      Moran|XXXXXXXXX|XXXXXXXXX|   5434 Middle Range|  Springfield|     MO|\n",
      "| 24|2013-07-25 00:00:...| 11441|         CLOSED|  11441|     Mary|   Ferguson|XXXXXXXXX|XXXXXXXXX|8702 Umber Mounta...|         Lutz|     FL|\n",
      "| 25|2013-07-25 00:00:...|  9503|         CLOSED|   9503|     Mary|Fitzpatrick|XXXXXXXXX|XXXXXXXXX|    7861 Honey Acres|      Orlando|     FL|\n",
      "| 26|2013-07-25 00:00:...|  7562|       COMPLETE|   7562|   Thomas|      Hayes|XXXXXXXXX|XXXXXXXXX|6639 Clear Fawn G...|    Escondido|     CA|\n",
      "| 27|2013-07-25 00:00:...|  3241|PENDING_PAYMENT|   3241|   Willie|      Smith|XXXXXXXXX|XXXXXXXXX|2075 Honey Panda ...|       Caguas|     PR|\n",
      "| 28|2013-07-25 00:00:...|   656|       COMPLETE|    656|    Julie|      Smith|XXXXXXXXX|XXXXXXXXX|9891 Golden Panda...|       Pomona|     CA|\n",
      "| 29|2013-07-25 00:00:...|   196|     PROCESSING|    196|   Thomas|     Watson|XXXXXXXXX|XXXXXXXXX|     4179 Merry Wood|     Dearborn|     MI|\n",
      "| 30|2013-07-25 00:00:...| 10039|PENDING_PAYMENT|  10039|     Mary|     Butler|XXXXXXXXX|XXXXXXXXX|    7786 Quiet Mall |       Conway|     AR|\n",
      "+---+--------------------+------+---------------+-------+---------+-----------+---------+---------+--------------------+-------------+-------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_df.join(customer_df,order_df.custid == customer_df.custids,\"left\").show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "796cbf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = order_df.join(customer_df,order_df.custid == customer_df.custids,\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cadb999c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511bf955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+---------------+-------+-----+---------+---------+---------+--------------------+-----------+-------+\n",
      "| id|                date|custid|         status|custids|fname|    lname| username|      pwd|                city|      state|pincode|\n",
      "+---+--------------------+------+---------------+-------+-----+---------+---------+---------+--------------------+-----------+-------+\n",
      "|  1|2013-07-25 00:00:...| 11599|         CLOSED|  11599| Mary|   Malone|XXXXXXXXX|XXXXXXXXX|8708 Indian Horse...|    Hickory|     NC|\n",
      "|  2|2013-07-25 00:00:...|   256|PENDING_PAYMENT|    256|David|Rodriguez|XXXXXXXXX|XXXXXXXXX|7605 Tawny Horse ...|    Chicago|     IL|\n",
      "|  3|2013-07-25 00:00:...| 12111|       COMPLETE|  12111|Amber|   Franco|XXXXXXXXX|XXXXXXXXX|8766 Clear Prairi...| Santa Cruz|     CA|\n",
      "|  4|2013-07-25 00:00:...|  8827|         CLOSED|   8827|Brian|   Wilson|XXXXXXXXX|XXXXXXXXX|   8396 High Corners|San Antonio|     TX|\n",
      "|  5|2013-07-25 00:00:...| 11318|       COMPLETE|  11318| Mary|    Henry|XXXXXXXXX|XXXXXXXXX|3047 Silent Ember...|     Caguas|     PR|\n",
      "+---+--------------------+------+---------------+-------+-----+---------+---------+---------+--------------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43517a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.write \\\n",
    ".mode(\"overwrite\") \\\n",
    ".option(\"header\",True) \\\n",
    ".partitionBy(\"status\") \\\n",
    ".option(\"path\",\"/user/itv014119/sample/joined\") \\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2215d6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
